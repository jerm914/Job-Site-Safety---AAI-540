{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e473eaad-50d7-4400-910a-41ee2a2c3ac3",
   "metadata": {},
   "source": [
    "# Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fea6bba-7513-4383-adcf-df2cd3ba3018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyathena in /opt/conda/lib/python3.10/site-packages (3.3.0)\n",
      "Requirement already satisfied: boto3>=1.26.4 in /opt/conda/lib/python3.10/site-packages (from pyathena) (1.33.9)\n",
      "Requirement already satisfied: botocore>=1.29.4 in /opt/conda/lib/python3.10/site-packages (from pyathena) (1.33.9)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from pyathena) (2022.7.1)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from pyathena) (8.0.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.26.4->pyathena) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.26.4->pyathena) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore>=1.29.4->pyathena) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore>=1.29.4->pyathena) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.29.4->pyathena) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.209.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.33.9)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.2)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.25.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.1.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.1)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.20.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.5.2)\n",
      "Requirement already satisfied: tblib<3,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.0.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.31.0)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.64.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker) (5.9.0)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.9 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.33.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker->sagemaker) (0.58.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (2023.11.17)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.31.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyathena\n",
    "!pip3 install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48bbf4-d38f-423a-b014-bf2599a7de15",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56617f56-6a2c-4d60-9b60-8d75ab10d4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3 # aws sdk for python\n",
    "import sagemaker # machine learning platform\n",
    "import numpy as np # array manipulation\n",
    "import os # operating system interfaces\n",
    "import pandas as pd # python data analysis\n",
    "import re # regular expressions\n",
    "from pyathena import connect # athena client\n",
    "from sagemaker.pytorch.estimator import PyTorch # PyTorch estimator\n",
    "from time import gmtime, strftime, sleep # time-related functions\n",
    "from sagemaker.pytorch.model import PyTorchModel # PyTorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e50ffb-1208-4663-bba0-a203890c410a",
   "metadata": {},
   "source": [
    "# Perform Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7735c026-0094-4bde-a03e-50336d86837a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory location: s3://sagemaker-us-east-1-752648173624/safety/data\n",
      "FeatureStore directory location: s3://sagemaker-us-east-1-752648173624/safety-featurestore\n",
      "\n",
      "Execution Role: arn:aws:iam::752648173624:role/LabRole\n"
     ]
    }
   ],
   "source": [
    "# establish sagemaker session, provide permissions\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# create a boto3 session for the sagemaker service\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)\n",
    "\n",
    "# client to make featurestore record calls\n",
    "featurestore_runtime = boto3.Session().client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "# create boto3 session to establish feature store session\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "# create featurestore session\n",
    "feature_store_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sm,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")\n",
    "\n",
    "# define prefixes for the safety data directory and featurestore\n",
    "prefix_data = 'safety/data'\n",
    "prefix_featurestore = 'safety-featurestore'\n",
    "\n",
    "# print s3 locations\n",
    "print('Data directory location:', f\"s3://{bucket}/{prefix_data}\")\n",
    "print('FeatureStore directory location:', f\"s3://{bucket}/{prefix_featurestore}\\n\")\n",
    "\n",
    "# print current IAM role for notebook instance\n",
    "role = sagemaker.get_execution_role()\n",
    "print('Execution Role:', role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ade40-dec1-4ea6-96fd-7fc4c2835c6e",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5549b1-2b6b-4b81-8162-a3c1b97ee351",
   "metadata": {},
   "source": [
    "## Query Catalog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad88c943-d9f4-41ab-bcab-95e8783d92d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query SELECT statement:\n",
      " SELECT * FROM safetydb.catalog_csv\n",
      "    WHERE img_filename like '%.jpg'\n",
      "    AND label_filename like '%.txt'\n",
      "    LIMIT 25000\n"
     ]
    }
   ],
   "source": [
    "# define database name\n",
    "database_name = 'safetydb'\n",
    "\n",
    "# define table name\n",
    "table_name_csv = 'catalog_csv'\n",
    "\n",
    "# set s3 temporary staging directory\n",
    "s3_staging_dir = \"s3://{0}/athena/staging\".format(bucket)\n",
    "\n",
    "# define connection parameters\n",
    "conn = connect(region_name=region, s3_staging_dir=s3_staging_dir)\n",
    "\n",
    "# define sql query statement\n",
    "statement = \"\"\"SELECT * FROM {}.{}\n",
    "    WHERE img_filename like '%.jpg'\n",
    "    AND label_filename like '%.txt'\n",
    "    LIMIT 25000\"\"\".format(\n",
    "    database_name, table_name_csv\n",
    ")\n",
    "\n",
    "# print sql statement for review before executing\n",
    "print('SQL query SELECT statement:\\n', statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47b28e4-95d6-4be9-bb4d-fff2cb4e5d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3197/3145676702.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_catalog_query = pd.read_sql(statement, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>img_filename</th>\n",
       "      <th>label_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001-checkpoint</td>\n",
       "      <td>000001-checkpoint.jpg</td>\n",
       "      <td>000001-checkpoint.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002-checkpoint</td>\n",
       "      <td>000002-checkpoint.jpg</td>\n",
       "      <td>000002-checkpoint.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>000001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000002</td>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>000002.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000003</td>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>000003.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000004</td>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>000004.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000005</td>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>000005.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000006</td>\n",
       "      <td>000006.jpg</td>\n",
       "      <td>000006.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000007</td>\n",
       "      <td>000007.jpg</td>\n",
       "      <td>000007.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000008</td>\n",
       "      <td>000008.jpg</td>\n",
       "      <td>000008.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sample_id           img_filename         label_filename\n",
       "0  000001-checkpoint  000001-checkpoint.jpg  000001-checkpoint.txt\n",
       "1  000002-checkpoint  000002-checkpoint.jpg  000002-checkpoint.txt\n",
       "2             000001             000001.jpg             000001.txt\n",
       "3             000002             000002.jpg             000002.txt\n",
       "4             000003             000003.jpg             000003.txt\n",
       "5             000004             000004.jpg             000004.txt\n",
       "6             000005             000005.jpg             000005.txt\n",
       "7             000006             000006.jpg             000006.txt\n",
       "8             000007             000007.jpg             000007.txt\n",
       "9             000008             000008.jpg             000008.txt"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute sql query and display results\n",
    "df_catalog_query = pd.read_sql(statement, conn)\n",
    "df_catalog_query.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c587ff-0c7a-42ec-b6b0-0d72d06af5cb",
   "metadata": {},
   "source": [
    "## Combine with FeatureGroup Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478284af-660f-44ff-94af-ba2d21b854e8",
   "metadata": {},
   "source": [
    "### Get Batch Records from FeatureGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf22ef3-75cd-4da7-a5cc-888d4b4bd04a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image FeatureGroup Name: image-feature-group-24-20-42-06\n",
      "Label FeatureGroup Name: label-feature-group-24-20-42-06\n"
     ]
    }
   ],
   "source": [
    "# define featuregroup name patterns\n",
    "image_feature_group_name_pattern = 'image-feature-group-'\n",
    "label_feature_group_name_pattern = 'label-feature-group-'\n",
    "\n",
    "# obtain latest version of featuregroup names, if multiples exist\n",
    "all_image_feature_groups = sm.list_feature_groups(NameContains=image_feature_group_name_pattern, SortBy='CreationTime', SortOrder='Descending')\n",
    "all_label_feature_groups = sm.list_feature_groups(NameContains=label_feature_group_name_pattern, SortBy='CreationTime', SortOrder='Descending')\n",
    "image_feature_group_name = all_image_feature_groups['FeatureGroupSummaries'][0]['FeatureGroupName']\n",
    "label_feature_group_name = all_label_feature_groups['FeatureGroupSummaries'][0]['FeatureGroupName']\n",
    "\n",
    "# print featuregroup names\n",
    "print('Image FeatureGroup Name:', image_feature_group_name)\n",
    "print('Label FeatureGroup Name:', label_feature_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685da3b7-c927-4b31-9040-6c89142c754c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# addresses limit of processing over 100 records in a batch\n",
    "def get_featuregroup_records(feature_group_name, record_identifiers_value):\n",
    "    \n",
    "    # create list to hold returned records\n",
    "    returned_records = []\n",
    "\n",
    "    # process each record id batch\n",
    "    for record_id_batch in record_identifiers_value:\n",
    "        featuregroup_records = featurestore_runtime.batch_get_record(\n",
    "            Identifiers=[\n",
    "                {\n",
    "                    'FeatureGroupName': feature_group_name,\n",
    "                    'RecordIdentifiersValueAsString': record_id_batch,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # add all received records to list\n",
    "        returned_records.extend(featuregroup_records['Records'])\n",
    "\n",
    "    # return all records from batches\n",
    "    return returned_records\n",
    "\n",
    "\n",
    "# specify record identifiers (i.e., sample ids) from previous catalog query\n",
    "record_identifiers_value = df_catalog_query['sample_id'].values.astype(str).tolist()\n",
    "\n",
    "# define batch size\n",
    "batch_size = 100\n",
    "\n",
    "# split record ids into batches, step by batch size\n",
    "record_id_batches = [record_identifiers_value[i:i+batch_size] for i in range(0, len(record_identifiers_value), batch_size)]\n",
    "\n",
    "# query image featuregroup by using record_id as primary key\n",
    "df_image_feature_group = get_featuregroup_records(image_feature_group_name, record_id_batches)\n",
    "\n",
    "# query label featuregroup by using record_id as primary key\n",
    "df_label_feature_group = get_featuregroup_records(label_feature_group_name, record_id_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545c9c87-50c0-4428-adcf-7ec7c769cfee",
   "metadata": {},
   "source": [
    "### Display Image FeatureGroup Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae6fb9e-fb30-4ddd-b3fc-809fa2ed163e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>img_format</th>\n",
       "      <th>img_mode</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000102</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000038</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000072</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000087</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000023</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id img_format img_mode img_height img_width\n",
       "0    000102       JPEG      RGB        640       640\n",
       "1    000038       JPEG      RGB        640       640\n",
       "2    000072       JPEG      RGB        640       640\n",
       "3    000087       JPEG      RGB        640       640\n",
       "4    000023       JPEG      RGB        640       640"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of image records and feature names, exclude eventtime\n",
    "# image_records = [sample['Record'] for sample in df_image_feature_group['Records']]\n",
    "image_records = [sample['Record'] for sample in df_image_feature_group]\n",
    "image_feature_names = [feature['FeatureName'] for feature in image_records[0] if feature['FeatureName'] != 'EventTime']\n",
    "\n",
    "# create list of image data\n",
    "image_data = [image_feature_names]\n",
    "\n",
    "# iterate through each record in image featuregroup\n",
    "for record in image_records:\n",
    "    \n",
    "    # iterate through each feature in individual record\n",
    "    image_data.append([feature['ValueAsString'] for feature in record if feature['FeatureName'] != 'EventTime'])\n",
    "                       \n",
    "# create images dataframe\n",
    "df_images = pd.DataFrame(image_data[1:], columns=image_data[0])\n",
    "                       \n",
    "# display dataframe head\n",
    "df_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184067b-e7c1-45aa-8874-3b03c04c17fa",
   "metadata": {},
   "source": [
    "### Display Label FeatureGroup Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ee1536-0dc1-45ab-8a2a-10c88a9840d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>count_helmet</th>\n",
       "      <th>count_vest</th>\n",
       "      <th>count_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000102</td>\n",
       "      <td>116</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000038</td>\n",
       "      <td>119</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000072</td>\n",
       "      <td>188</td>\n",
       "      <td>19</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000023</td>\n",
       "      <td>177</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000087</td>\n",
       "      <td>163</td>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id count_helmet count_vest count_head\n",
       "0    000102          116         11         33\n",
       "1    000038          119         11         33\n",
       "2    000072          188         19         61\n",
       "3    000023          177         19         59\n",
       "4    000087          163         19         35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of label records and feature names, exclude eventtime\n",
    "# label_records = [sample['Record'] for sample in df_label_feature_group['Records']]\n",
    "label_records = [sample['Record'] for sample in df_label_feature_group]\n",
    "label_feature_names = [feature['FeatureName'] for feature in label_records[0] if feature['FeatureName'] != 'EventTime']\n",
    "\n",
    "# create list of label data\n",
    "label_data = [label_feature_names]\n",
    "\n",
    "# iterate through each record in label featuregroup\n",
    "for record in label_records:\n",
    "    \n",
    "    # iterate through each feature in individual record\n",
    "    label_data.append([feature['ValueAsString'] for feature in record if feature['FeatureName'] != 'EventTime'])\n",
    "                       \n",
    "# create labels dataframe\n",
    "df_labels = pd.DataFrame(label_data[1:], columns=label_data[0])\n",
    "                       \n",
    "# display dataframe head\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd85fc-f5cd-45f9-acbc-679479d822cb",
   "metadata": {},
   "source": [
    "### Join Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3731579c-abd3-4587-b200-1968c641fe73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>img_filename</th>\n",
       "      <th>label_filename</th>\n",
       "      <th>img_format</th>\n",
       "      <th>img_mode</th>\n",
       "      <th>img_height</th>\n",
       "      <th>img_width</th>\n",
       "      <th>count_helmet</th>\n",
       "      <th>count_vest</th>\n",
       "      <th>count_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>000001.txt</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>211</td>\n",
       "      <td>21</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>000002.txt</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003</td>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>000003.txt</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>115</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004</td>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>000004.txt</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005</td>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>000005.txt</td>\n",
       "      <td>JPEG</td>\n",
       "      <td>RGB</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>173</td>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id img_filename label_filename img_format img_mode img_height  \\\n",
       "0    000001   000001.jpg     000001.txt       JPEG      RGB        640   \n",
       "1    000002   000002.jpg     000002.txt       JPEG      RGB        640   \n",
       "2    000003   000003.jpg     000003.txt       JPEG      RGB        640   \n",
       "3    000004   000004.jpg     000004.txt       JPEG      RGB        640   \n",
       "4    000005   000005.jpg     000005.txt       JPEG      RGB        640   \n",
       "\n",
       "  img_width count_helmet count_vest count_head  \n",
       "0       640          211         21         69  \n",
       "1       640           15          1          0  \n",
       "2       640          115         11         33  \n",
       "3       640           78          4         23  \n",
       "4       640          173         19         35  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge catalog query and images dataframes, then the resulting with labels dataframe\n",
    "df_combined = pd.merge(df_catalog_query, df_images, on='sample_id')\n",
    "df_combined = pd.merge(df_combined, df_labels, on='sample_id')\n",
    "\n",
    "# display resulting datafrmae\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6845240-c8a3-45a3-a639-e0d87def0700",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734ba1fc-755d-4d31-b236-bc50d6c60a60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Splits:\n",
      "------------\n",
      "Train :   40 samples\n",
      "Val   :   7 samples\n",
      "Test  :   7 samples\n",
      "Batch :   29 samples\n"
     ]
    }
   ],
   "source": [
    "# use a copy of dataframe, can manipulate if desired for experimentation\n",
    "data = df_combined.copy()\n",
    "\n",
    "# data split in four sets - training, validation, test, and batch inference\n",
    "rand_split = np.random.rand(len(data))\n",
    "train_list = rand_split < 0.4\n",
    "val_list = (rand_split >= 0.4) & (rand_split < 0.5)\n",
    "test_list = (rand_split >= 0.5) & (rand_split < 0.6)\n",
    "batch_list = rand_split >= 0.6 # \"production\" data\n",
    "\n",
    "# print data splits\n",
    "print('Data Splits:')\n",
    "print('------------')\n",
    "print(f\"Train :   {sum(train_list)} samples\")\n",
    "print(f\"Val   :   {sum(val_list)} samples\")\n",
    "print(f\"Test  :   {sum(test_list)} samples\")\n",
    "print(f\"Batch :   {sum(batch_list)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b0b53-c0f5-48db-a095-d0ee8f2d175d",
   "metadata": {},
   "source": [
    "## Create Split Datasets in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d6c1b29-3977-49d1-9c56-a8ab90267061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images source directory location: s3://sagemaker-us-east-1-752648173624/safety/data/images/\n",
      "Labels source directory location: s3://sagemaker-us-east-1-752648173624/safety/data/labels/ \n",
      "\n",
      "Split destination directory location: s3://sagemaker-us-east-1-752648173624/safety/data/split/\n"
     ]
    }
   ],
   "source": [
    "# define and print source s3 locations\n",
    "s3_images_source = f\"s3://{bucket}/{prefix_data}/images/\"\n",
    "s3_labels_source = f\"s3://{bucket}/{prefix_data}/labels/\"\n",
    "print('Images source directory location:', s3_images_source)\n",
    "print('Labels source directory location:', s3_labels_source, '\\n')\n",
    "\n",
    "# define and print destination s3 location for data splits\n",
    "s3_split_dest = f\"s3://{bucket}/{prefix_data}/split/\"\n",
    "print('Split destination directory location:', s3_split_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b7727e-d8cc-4e70-89e4-79e0970740d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define function to copy files for respective data splits to corresponding s3 destinations\n",
    "# provide 'split_name' as either 'train', 'val', 'test', or 'batch'\n",
    "# provide 'split_list' as either 'train_list', 'val_list', 'test_list', or 'batch_list'\n",
    "def split_dataset(split_name, split_list):\n",
    "\n",
    "    # iterate through each sample in split\n",
    "    for index, sample in data[split_list].iterrows():\n",
    "\n",
    "        # source/destination variables for individual sample\n",
    "        cp_image_source = f\"{s3_images_source}{sample['img_filename']}\"\n",
    "        cp_image_dest = f\"{s3_split_dest}{split_name}/images/\"\n",
    "        cp_label_source = f\"{s3_labels_source}{sample['label_filename']}\"\n",
    "        cp_label_dest = f\"{s3_split_dest}{split_name}/labels/\"\n",
    "\n",
    "        # copy from source to destination\n",
    "        !aws s3 cp $cp_image_source $cp_image_dest\n",
    "        !aws s3 cp $cp_label_source $cp_label_dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27d9bd4b-5eee-42d5-b1b8-cf402f5e516f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning TRAIN data split copies.\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000002.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000002.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000002.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000002.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000004.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000004.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000004.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000004.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000006.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000006.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000006.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000006.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000012.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000012.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000012.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000012.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000014.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000014.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000014.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000014.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000015.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000015.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000015.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000015.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000016.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000016.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000016.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000016.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000017.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000017.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000017.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000017.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000019.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000019.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000019.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000019.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000020.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000020.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000020.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000020.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000027.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000027.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000027.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000027.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000028.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000028.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000028.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000028.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000029.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000029.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000029.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000029.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000030.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000030.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000030.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000030.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000032.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000032.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000032.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000032.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000035.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000035.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000035.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000035.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000039.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000039.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000039.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000039.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000041.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000041.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000041.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000041.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000043.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000043.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000043.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000043.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000044.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000044.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000044.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000044.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000045.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000045.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000045.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000045.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000049.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000049.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000049.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000049.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000051.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000051.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000051.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000051.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000053.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000053.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000053.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000053.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000054.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000054.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000054.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000054.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000062.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000062.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000062.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000062.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000064.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000064.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000064.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000064.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000065.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000065.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000065.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000065.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000069.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000069.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000069.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000069.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000070.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000070.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000070.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000070.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000072.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000072.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000072.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000072.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000076.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000076.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000076.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000076.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000085.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000085.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000085.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000085.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000089.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000089.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000089.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000089.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000091.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000091.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000091.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000091.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000099.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000099.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000099.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000099.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000101.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000101.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000101.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000101.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000103.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000103.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000103.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000103.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000106.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000106.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000106.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000106.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000107.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/images/000107.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000107.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/train/labels/000107.txt\n",
      "Completed TRAIN data split copies.\n",
      "\n",
      "Beginning VAL data split copies.\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000001.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/images/000001.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000001.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/labels/000001.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000007.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/images/000007.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000007.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/labels/000007.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000009.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/images/000009.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000009.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/labels/000009.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000026.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/images/000026.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000026.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/labels/000026.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000061.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/images/000061.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000061.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/labels/000061.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000082.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/images/000082.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000082.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/labels/000082.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000087.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/images/000087.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000087.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/val/labels/000087.txt\n",
      "Completed VAL data split copies.\n",
      "\n",
      "Beginning TEST data split copies.\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000008.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/images/000008.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000008.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/labels/000008.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000038.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/images/000038.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000038.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/labels/000038.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000042.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/images/000042.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000042.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/labels/000042.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000047.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/images/000047.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000047.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/labels/000047.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000060.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/images/000060.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000060.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/labels/000060.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000086.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/images/000086.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000086.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/labels/000086.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000090.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/images/000090.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000090.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/test/labels/000090.txt\n",
      "Completed TEST data split copies.\n",
      "\n",
      "Beginning BATCH data split copies.\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000003.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000003.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000003.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000003.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000005.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000005.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000005.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000005.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000010.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000010.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000010.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000010.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000011.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000011.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000011.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000011.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000013.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000013.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000013.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000013.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000018.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000018.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000018.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000018.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000023.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000023.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000023.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000023.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000025.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000025.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000025.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000025.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000031.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000031.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000031.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000031.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000033.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000033.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000033.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000033.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000037.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000037.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000037.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000037.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000040.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000040.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000040.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000040.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000046.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000046.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000046.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000046.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000048.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000048.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000048.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000048.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000050.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000050.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000050.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000050.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000052.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000052.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000052.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000052.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000055.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000055.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000055.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000055.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000059.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000059.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000059.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000059.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000066.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000066.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000066.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000066.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000067.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000067.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000067.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000067.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000073.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000073.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000073.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000073.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000074.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000074.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000074.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000074.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000077.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000077.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000077.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000077.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000078.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000078.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000078.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000078.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000081.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000081.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000081.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000081.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000096.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000096.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000096.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000096.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000098.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000098.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000098.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000098.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000100.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000100.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000100.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000100.txt\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/images/000102.jpg to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/images/000102.jpg\n",
      "copy: s3://sagemaker-us-east-1-752648173624/safety/data/labels/000102.txt to s3://sagemaker-us-east-1-752648173624/safety/data/split/batch/labels/000102.txt\n",
      "Completed BATCH data split copies.\n"
     ]
    }
   ],
   "source": [
    "# perform data copies\n",
    "print('Beginning TRAIN data split copies.')\n",
    "split_dataset(split_name='train', split_list=train_list)\n",
    "print('Completed TRAIN data split copies.\\n')\n",
    "\n",
    "print('Beginning VAL data split copies.')\n",
    "split_dataset(split_name='val', split_list=val_list)\n",
    "print('Completed VAL data split copies.\\n')\n",
    "\n",
    "print('Beginning TEST data split copies.')\n",
    "split_dataset(split_name='test', split_list=test_list)\n",
    "print('Completed TEST data split copies.\\n')\n",
    "\n",
    "print('Beginning BATCH data split copies.')\n",
    "split_dataset(split_name='batch', split_list=batch_list)\n",
    "print('Completed BATCH data split copies.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd7dfc0-e357-4eba-84a3-9b455b9d4c60",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Job and Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f3e67-2d56-49b1-9c9b-1abec7b6d243",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and Run Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cc59507-eef2-4a8c-b6e5-f5ab063581af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: yolov8-2024-02-24-21-38-30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-24 21:38:31 Starting - Starting the training job...\n",
      "2024-02-24 21:38:46 Starting - Preparing the instances for training...\n",
      "2024-02-24 21:39:17 Downloading - Downloading input data...\n",
      "2024-02-24 21:39:47 Downloading - Downloading the training image......\n",
      "2024-02-24 21:40:32 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:42,868 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:42,869 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:42,869 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:42,879 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:42,882 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:44,375 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (10.1.0)\u001b[0m\n",
      "\u001b[34mCollecting ultralytics==8.1.9 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading ultralytics-8.1.9-py3-none-any.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.2/40.2 kB 5.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting dill==0.3.8 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (1.26.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (4.8.1.78)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (2.31.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (1.11.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (0.15.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mCollecting py-cpuinfo (from ultralytics==8.1.9->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\u001b[0m\n",
      "\u001b[34mCollecting thop>=0.1.1 (from ultralytics==8.1.9->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.9->-r requirements.txt (line 2)) (0.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (4.45.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (1.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (23.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.1.9->-r requirements.txt (line 2)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.1.9->-r requirements.txt (line 2)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (2023.11.17)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (3.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics==8.1.9->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[34mDownloading ultralytics-8.1.9-py3-none-any.whl (709 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 709.3/709.3 kB 58.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.8-py3-none-any.whl (116 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 19.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: py-cpuinfo, dill, thop, ultralytics\u001b[0m\n",
      "\u001b[34mAttempting uninstall: dill\u001b[0m\n",
      "\u001b[34mFound existing installation: dill 0.3.7\u001b[0m\n",
      "\u001b[34mUninstalling dill-0.3.7:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled dill-0.3.7\u001b[0m\n",
      "\u001b[34mSuccessfully installed dill-0.3.8 py-cpuinfo-9.0.0 thop-0.1.1.post2209072238 ultralytics-8.1.9\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.1 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,021 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,021 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,022 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,023 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,034 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,034 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,045 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,046 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,056 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"data\": \"data.yaml\",\n",
      "        \"epochs\": 5,\n",
      "        \"saved_model_name\": \"model.pt\",\n",
      "        \"yolo_model\": \"yolov8n.pt\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"yolov8-2024-02-24-21-38-30\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-752648173624/yolov8-2024-02-24-21-38-30/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"data\":\"data.yaml\",\"epochs\":5,\"saved_model_name\":\"model.pt\",\"yolo_model\":\"yolov8n.pt\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-752648173624/yolov8-2024-02-24-21-38-30/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"data\":\"data.yaml\",\"epochs\":5,\"saved_model_name\":\"model.pt\",\"yolo_model\":\"yolov8n.pt\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"yolov8-2024-02-24-21-38-30\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-752648173624/yolov8-2024-02-24-21-38-30/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--data\",\"data.yaml\",\"--epochs\",\"5\",\"--saved_model_name\",\"model.pt\",\"--yolo_model\",\"yolov8n.pt\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_DATA=data.yaml\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_SAVED_MODEL_NAME=model.pt\u001b[0m\n",
      "\u001b[34mSM_HP_YOLO_MODEL=yolov8n.pt\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 train.py --data data.yaml --epochs 5 --saved_model_name model.pt --yolo_model yolov8n.pt\u001b[0m\n",
      "\u001b[34m2024-02-24 21:40:48,082 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mDownloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\u001b[0m\n",
      "\u001b[34m0%|          | 0.00/6.23M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 6.23M/6.23M [00:00<00:00, 319MB/s]\u001b[0m\n",
      "\u001b[34mNew https://pypi.org/project/ultralytics/8.1.18 available 😃 Update with 'pip install -U ultralytics'\u001b[0m\n",
      "\u001b[34mUltralytics YOLOv8.1.9 🚀 Python-3.10.8 torch-2.0.1 CPU (Intel Xeon Platinum 8259CL 2.50GHz)\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mengine/trainer: #033[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=5, time=None, patience=50, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\u001b[0m\n",
      "\u001b[34mDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\u001b[0m\n",
      "\u001b[34m0%|          | 0.00/755k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 755k/755k [00:00<00:00, 83.1MB/s]\u001b[0m\n",
      "\u001b[34mOverriding model.yaml nc=80 with nc=3\u001b[0m\n",
      "\u001b[34mfrom  n    params  module                                       arguments\u001b[0m\n",
      "\u001b[34m0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]\u001b[0m\n",
      "\u001b[34m1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]\u001b[0m\n",
      "\u001b[34m2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]\u001b[0m\n",
      "\u001b[34m3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]\u001b[0m\n",
      "\u001b[34m4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]\u001b[0m\n",
      "\u001b[34m5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]\u001b[0m\n",
      "\u001b[34m6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]\u001b[0m\n",
      "\u001b[34m7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]\u001b[0m\n",
      "\u001b[34m8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]\u001b[0m\n",
      "\u001b[34m9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]\u001b[0m\n",
      "\u001b[34m10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']\u001b[0m\n",
      "\u001b[34m11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]\u001b[0m\n",
      "\u001b[34m12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]\u001b[0m\n",
      "\u001b[34m13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']\u001b[0m\n",
      "\u001b[34m14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]\u001b[0m\n",
      "\u001b[34m15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]\u001b[0m\n",
      "\u001b[34m16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]\u001b[0m\n",
      "\u001b[34m17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]\u001b[0m\n",
      "\u001b[34m18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]\u001b[0m\n",
      "\u001b[34m19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]\u001b[0m\n",
      "\u001b[34m20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]\u001b[0m\n",
      "\u001b[34m21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]\u001b[0m\n",
      "\u001b[34m22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]\u001b[0m\n",
      "\u001b[34mModel summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\u001b[0m\n",
      "\u001b[34mTransferred 319/355 items from pretrained weights\u001b[0m\n",
      "\u001b[34mFreezing layer 'model.22.dfl.conv.weight'\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mAutoBatch: #033[0mComputing optimal batch size for imgsz=640\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mAutoBatch: #033[0mCUDA not detected, using default CPU batch-size 16\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mtrain: #033[0mScanning /opt/ml/input/data/training/train/labels...:   0%|          | 0/68 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mtrain: #033[0mScanning /opt/ml/input/data/training/train/labels... 68 images, 0 backgrounds, 0 corrupt: 100%|██████████| 68/68 [00:00<00:00, 1483.90it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mtrain: #033[0mNew cache created: /opt/ml/input/data/training/train/labels.cache\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mval: #033[0mScanning /opt/ml/input/data/training/val/labels...:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mval: #033[0mScanning /opt/ml/input/data/training/val/labels... 29 images, 0 backgrounds, 0 corrupt: 100%|██████████| 29/29 [00:00<00:00, 1741.82it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mval: #033[0mNew cache created: /opt/ml/input/data/training/val/labels.cache\u001b[0m\n",
      "\u001b[34mPlotting labels to runs/detect/train/labels.jpg...\u001b[0m\n",
      "\u001b[34m#033[34m#033[1moptimizer:#033[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically...\u001b[0m\n",
      "\u001b[34m#033[34m#033[1moptimizer:#033[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\u001b[0m\n",
      "\u001b[34mImage sizes 640 train, 640 val\u001b[0m\n",
      "\u001b[34mUsing 0 dataloader workers\u001b[0m\n",
      "\u001b[34mLogging results to #033[1mruns/detect/train#033[0m\u001b[0m\n",
      "\u001b[34mStarting training for 5 epochs...\u001b[0m\n",
      "\u001b[34mEpoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m1/5         0G      1.863       4.13      1.657         62        640:   0%|          | 0/5 [00:06<?, ?it/s]\u001b[0m\n",
      "\u001b[34m1/5         0G      1.863       4.13      1.657         62        640:  20%|██        | 1/5 [00:06<00:25,  6.34s/it]\u001b[0m\n",
      "\u001b[34m1/5         0G       1.91      4.104      1.598         92        640:  20%|██        | 1/5 [00:11<00:25,  6.34s/it]\u001b[0m\n",
      "\u001b[34m1/5         0G       1.91      4.104      1.598         92        640:  40%|████      | 2/5 [00:11<00:17,  5.84s/it]\u001b[0m\n",
      "\u001b[34m1/5         0G      2.058      4.107      1.673         96        640:  40%|████      | 2/5 [00:16<00:17,  5.84s/it]\u001b[0m\n",
      "\u001b[34m1/5         0G      2.058      4.107      1.673         96        640:  60%|██████    | 3/5 [00:16<00:10,  5.48s/it]\u001b[0m\n",
      "\u001b[34m1/5         0G      2.056      4.096      1.661        110        640:  60%|██████    | 3/5 [00:21<00:10,  5.48s/it]\u001b[0m\n",
      "\u001b[34m1/5         0G      2.056      4.096      1.661        110        640:  80%|████████  | 4/5 [00:21<00:05,  5.09s/it]\u001b[0m\n",
      "\u001b[34m1/5         0G      2.021      4.034      1.662         27        640:  80%|████████  | 4/5 [00:22<00:05,  5.09s/it]\u001b[0m\n",
      "\u001b[34m1/5         0G      2.021      4.034      1.662         27        640: 100%|██████████| 5/5 [00:22<00:00,  3.67s/it]#015        1/5         0G      2.021      4.034      1.662         27        640: 100%|██████████| 5/5 [00:22<00:00,  4.50s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.09s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.09s/it]\u001b[0m\n",
      "\u001b[34mall         29        108    0.00198      0.213    0.00227   0.000753\u001b[0m\n",
      "\u001b[34mEpoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.616      3.608      1.546         67        640:   0%|          | 0/5 [00:04<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.616      3.608      1.546         67        640:  20%|██        | 1/5 [00:04<00:17,  4.36s/it]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.701       3.68       1.52        100        640:  20%|██        | 1/5 [00:08<00:17,  4.36s/it]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.701       3.68       1.52        100        640:  40%|████      | 2/5 [00:08<00:13,  4.34s/it]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.727      3.803       1.49         92        640:  40%|████      | 2/5 [00:12<00:13,  4.34s/it]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.727      3.803       1.49         92        640:  60%|██████    | 3/5 [00:12<00:08,  4.24s/it]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.741      3.747      1.505         94        640:  60%|██████    | 3/5 [00:16<00:08,  4.24s/it]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.741      3.747      1.505         94        640:  80%|████████  | 4/5 [00:16<00:04,  4.20s/it]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.691      3.751      1.492          9        640:  80%|████████  | 4/5 [00:18<00:04,  4.20s/it]\u001b[0m\n",
      "\u001b[34m2/5         0G      1.691      3.751      1.492          9        640: 100%|██████████| 5/5 [00:18<00:00,  3.08s/it]#015        2/5         0G      1.691      3.751      1.492          9        640: 100%|██████████| 5/5 [00:18<00:00,  3.61s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\u001b[0m\n",
      "\u001b[34mall         29        108    0.00377      0.291     0.0142    0.00659\u001b[0m\n",
      "\u001b[34mEpoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.579        3.3      1.386        101        640:   0%|          | 0/5 [00:04<?, ?it/s]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.579        3.3      1.386        101        640:  20%|██        | 1/5 [00:04<00:16,  4.08s/it]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.584      3.339      1.376         81        640:  20%|██        | 1/5 [00:08<00:16,  4.08s/it]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.584      3.339      1.376         81        640:  40%|████      | 2/5 [00:08<00:12,  4.17s/it]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.508      3.233      1.312         89        640:  40%|████      | 2/5 [00:12<00:12,  4.17s/it]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.508      3.233      1.312         89        640:  60%|██████    | 3/5 [00:12<00:08,  4.13s/it]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.513      3.177      1.316         76        640:  60%|██████    | 3/5 [00:16<00:08,  4.13s/it]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.513      3.177      1.316         76        640:  80%|████████  | 4/5 [00:16<00:04,  4.28s/it]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.613      3.231      1.378         28        640:  80%|████████  | 4/5 [00:18<00:04,  4.28s/it]\u001b[0m\n",
      "\u001b[34m3/5         0G      1.613      3.231      1.378         28        640: 100%|██████████| 5/5 [00:18<00:00,  3.21s/it]#015        3/5         0G      1.613      3.231      1.378         28        640: 100%|██████████| 5/5 [00:18<00:00,  3.65s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\u001b[0m\n",
      "\u001b[34mall         29        108    0.00565       0.33     0.0434     0.0234\u001b[0m\n",
      "\u001b[34mEpoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.432      2.841      1.175         65        640:   0%|          | 0/5 [00:04<?, ?it/s]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.432      2.841      1.175         65        640:  20%|██        | 1/5 [00:04<00:16,  4.16s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.477      2.593      1.223         67        640:  20%|██        | 1/5 [00:08<00:16,  4.16s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.477      2.593      1.223         67        640:  40%|████      | 2/5 [00:08<00:12,  4.21s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.497      2.622      1.245         71        640:  40%|████      | 2/5 [00:12<00:12,  4.21s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.497      2.622      1.245         71        640:  60%|██████    | 3/5 [00:12<00:08,  4.13s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.562      2.662      1.295         63        640:  60%|██████    | 3/5 [00:16<00:08,  4.13s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.562      2.662      1.295         63        640:  80%|████████  | 4/5 [00:16<00:04,  4.14s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.549      2.621      1.302          9        640:  80%|████████  | 4/5 [00:17<00:04,  4.14s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.549      2.621      1.302          9        640: 100%|██████████| 5/5 [00:17<00:00,  3.01s/it]\u001b[0m\n",
      "\u001b[34m4/5         0G      1.549      2.621      1.302          9        640: 100%|██████████| 5/5 [00:17<00:00,  3.52s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\u001b[0m\n",
      "\u001b[34mall         29        108    0.00628      0.455     0.0578     0.0312\u001b[0m\n",
      "\u001b[34mEpoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.413      2.363      1.217         83        640:   0%|          | 0/5 [00:04<?, ?it/s]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.413      2.363      1.217         83        640:  20%|██        | 1/5 [00:04<00:16,  4.19s/it]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.482      2.426      1.244         64        640:  20%|██        | 1/5 [00:08<00:16,  4.19s/it]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.482      2.426      1.244         64        640:  40%|████      | 2/5 [00:08<00:12,  4.22s/it]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.503      2.453      1.247         87        640:  40%|████      | 2/5 [00:12<00:12,  4.22s/it]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.503      2.453      1.247         87        640:  60%|██████    | 3/5 [00:12<00:08,  4.23s/it]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.509      2.491      1.255         76        640:  60%|██████    | 3/5 [00:16<00:08,  4.23s/it]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.509      2.491      1.255         76        640:  80%|████████  | 4/5 [00:16<00:04,  4.22s/it]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.513      2.441      1.244         40        640:  80%|████████  | 4/5 [00:17<00:04,  4.22s/it]#015        5/5         0G      1.513      2.441      1.244         40        640: 100%|██████████| 5/5 [00:17<00:00,  3.09s/it]\u001b[0m\n",
      "\u001b[34m5/5         0G      1.513      2.441      1.244         40        640: 100%|██████████| 5/5 [00:17<00:00,  3.59s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\u001b[0m\n",
      "\u001b[34mall         29        108    0.00667      0.493     0.0732     0.0393\u001b[0m\n",
      "\u001b[34m5 epochs completed in 0.032 hours.\u001b[0m\n",
      "\u001b[34mOptimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\u001b[0m\n",
      "\u001b[34mOptimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\u001b[0m\n",
      "\u001b[34mValidating runs/detect/train/weights/best.pt...\u001b[0m\n",
      "\u001b[34mUltralytics YOLOv8.1.9 🚀 Python-3.10.8 torch-2.0.1 CPU (Intel Xeon Platinum 8259CL 2.50GHz)\u001b[0m\n",
      "\u001b[34mModel summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\u001b[0m\n",
      "\u001b[34mall         29        108    0.00685      0.496     0.0729      0.039\u001b[0m\n",
      "\u001b[34mhelmet         29         86     0.0167      0.395       0.17      0.089\u001b[0m\n",
      "\u001b[34mvest         29          9     0.0023      0.556    0.00791      0.005\n",
      "                  head         29         13    0.00156      0.538     0.0406      0.023\u001b[0m\n",
      "\u001b[34mSpeed: 0.8ms preprocess, 76.4ms inference, 0.0ms loss, 16.4ms postprocess per image\u001b[0m\n",
      "\u001b[34mResults saved to #033[1mruns/detect/train#033[0m\u001b[0m\n",
      "\u001b[34mEVALUATING MODEL ON TEST DATASET...\u001b[0m\n",
      "\u001b[34mUltralytics YOLOv8.1.9 🚀 Python-3.10.8 torch-2.0.1 CPU (Intel Xeon Platinum 8259CL 2.50GHz)\u001b[0m\n",
      "\u001b[34mModel summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mval: #033[0mScanning /opt/ml/input/data/training/test/labels...:   0%|          | 0/34 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mval: #033[0mScanning /opt/ml/input/data/training/test/labels... 34 images, 0 backgrounds, 0 corrupt: 100%|██████████| 34/34 [00:00<00:00, 1225.32it/s]\u001b[0m\n",
      "\u001b[34m#033[34m#033[1mval: #033[0mNew cache created: /opt/ml/input/data/training/test/labels.cache\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:01<00:03,  1.95s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:03<00:01,  1.85s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:04<00:00,  1.20s/it]\u001b[0m\n",
      "\u001b[34mClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:04<00:00,  1.38s/it]\u001b[0m\n",
      "\u001b[34mall         34        118    0.00652      0.557      0.188      0.112\u001b[0m\n",
      "\u001b[34mhelmet         34         74     0.0127      0.419       0.29      0.178\n",
      "                  vest         34         14    0.00414      0.786      0.183      0.105\u001b[0m\n",
      "\u001b[34mhead         34         30    0.00274      0.467     0.0912     0.0524\u001b[0m\n",
      "\u001b[34mSpeed: 1.2ms preprocess, 90.4ms inference, 0.0ms loss, 15.5ms postprocess per image\u001b[0m\n",
      "\u001b[34mResults saved to #033[1mruns/detect/val#033[0m\u001b[0m\n",
      "\u001b[34m-------------\u001b[0m\n",
      "\u001b[34m-------------\u001b[0m\n",
      "\u001b[34m-------------\u001b[0m\n",
      "\u001b[34mMODEL EVALUATION METRIC:\u001b[0m\n",
      "\u001b[34mmAP50: 0.1879\u001b[0m\n",
      "\u001b[34m-------------\u001b[0m\n",
      "\u001b[34m-------------\u001b[0m\n",
      "\u001b[34m-------------\u001b[0m\n",
      "\u001b[34m2024-02-24 21:43:10,569 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-24 21:43:10,570 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-24 21:43:10,570 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-02-24 21:43:24 Uploading - Uploading generated training model\n",
      "2024-02-24 21:43:24 Completed - Training job completed\n",
      "Training seconds: 248\n",
      "Billable seconds: 248\n",
      "CPU times: user 680 ms, sys: 69.6 ms, total: 750 ms\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# define job name and output location\n",
    "job_name = 'yolov8-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_location = \"s3://{}/{}/output/{}\".format(bucket, prefix_data, job_name)\n",
    "\n",
    "# build a PyTorch estimator\n",
    "pytorch_estimator = PyTorch(\n",
    "    role=role,\n",
    "    entry_point='train.py', # custom training script, locate in code directory\n",
    "    framework_version='2.0.1', # training - CPU - Python 3.10\n",
    "    py_version='py310',\n",
    "    source_dir='./code',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sess,\n",
    "    hyperparameters = {'data': 'data.yaml', # yaml config file for custom dataset\n",
    "                       'epochs': 5, # number of training epochs\n",
    "                       'yolo_model': 'yolov8n.pt', # pretrained base model\n",
    "                       'saved_model_name': 'model.pt' # name for model export\n",
    "                      }\n",
    ")\n",
    "\n",
    "# s3 location where training data is saved\n",
    "inputs = s3_split_dest[:-1]\n",
    "\n",
    "# begin training job\n",
    "pytorch_estimator.fit(inputs=inputs, job_name=job_name, logs='All')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ec59e-08ef-4e4d-9cc3-2e74d7898db4",
   "metadata": {},
   "source": [
    "## Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29451de5-bab2-4580-b100-45dd3490d23f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-752648173624/safety/data/output/yolov8-2024-02-24-21-38-30/yolov8-2024-02-24-21-38-30/output/model.tar.gz), script artifact (code), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-752648173624/pytorch-inference-2024-02-24-21-43-45-468/model.tar.gz. This may take some time depending on model size...\n"
     ]
    },
    {
     "ename": "PythonVersionError",
     "evalue": "Since tarfile extraction is unsafe the operation is prohibited per PEP-721. Please update your Python [3.10.6 (main, Oct  7 2022, 20:19:58) [GCC 11.2.0]] to latest patch [refer to https://www.python.org/downloads/] to consume the security patch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonVersionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:20\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/model.py:1751\u001b[0m, in \u001b[0;36mModel.transformer\u001b[0;34m(self, instance_count, instance_type, strategy, assemble_with, output_path, output_kms_key, accept, env, max_concurrent_transforms, max_payload, tags, volume_kms_key)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_sagemaker_session_if_does_not_exist(instance_type)\n\u001b[1;32m   1749\u001b[0m tags \u001b[38;5;241m=\u001b[39m format_tags(tags)\n\u001b[0;32m-> 1751\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_sagemaker_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_network_isolation():\n\u001b[1;32m   1753\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/model.py:857\u001b[0m, in \u001b[0;36mModel._create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags, serverless_inference_config, accept_eula)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m model_package\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m     container_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_container_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_eula\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_eula\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session, PipelineSession):\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# _base_name, model_name are not needed under PipelineSession.\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;66;03m# the model_data may be Pipeline variable\u001b[39;00m\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# which may break the _base_name generation\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_base_name_if_needed(\n\u001b[1;32m    869\u001b[0m             image_uri\u001b[38;5;241m=\u001b[39mcontainer_def[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    870\u001b[0m             script_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_dir,\n\u001b[1;32m    871\u001b[0m             model_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_uri(),\n\u001b[1;32m    872\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/pytorch/model.py:315\u001b[0m, in \u001b[0;36mPyTorchModel.prepare_container_def\u001b[0;34m(self, instance_type, accelerator_type, serverless_inference_config, accept_eula)\u001b[0m\n\u001b[1;32m    307\u001b[0m     deploy_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserving_image_uri(\n\u001b[1;32m    308\u001b[0m         region_name,\n\u001b[1;32m    309\u001b[0m         instance_type,\n\u001b[1;32m    310\u001b[0m         accelerator_type\u001b[38;5;241m=\u001b[39maccelerator_type,\n\u001b[1;32m    311\u001b[0m         serverless_inference_config\u001b[38;5;241m=\u001b[39mserverless_inference_config,\n\u001b[1;32m    312\u001b[0m     )\n\u001b[1;32m    314\u001b[0m deploy_key_prefix \u001b[38;5;241m=\u001b[39m model_code_key_prefix(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_prefix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, deploy_image)\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeploy_key_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_mms_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m deploy_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)\n\u001b[1;32m    317\u001b[0m deploy_env\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_script_mode_env_vars())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/model.py:755\u001b[0m, in \u001b[0;36mModel._upload_code\u001b[0;34m(self, key_prefix, repack)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code \u001b[38;5;241m=\u001b[39m fw_utils\u001b[38;5;241m.\u001b[39mUploadedCode(\n\u001b[1;32m    740\u001b[0m         s3_prefix\u001b[38;5;241m=\u001b[39mrepacked_model_data,\n\u001b[1;32m    741\u001b[0m         script_name\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentry_point),\n\u001b[1;32m    742\u001b[0m     )\n\u001b[1;32m    744\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepacking model artifact (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m), script artifact \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m), and dependencies (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m     repacked_model_data,\n\u001b[1;32m    753\u001b[0m )\n\u001b[0;32m--> 755\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepack_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_script\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepacked_model_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepacked_model_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepacked_model_data \u001b[38;5;241m=\u001b[39m repacked_model_data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/utils.py:542\u001b[0m, in \u001b[0;36mrepack_model\u001b[0;34m(inference_script, source_directory, dependencies, model_uri, repacked_model_uri, sagemaker_session, kms_key)\u001b[0m\n\u001b[1;32m    535\u001b[0m local_download_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sagemaker_session\u001b[38;5;241m.\u001b[39msettings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m sagemaker_session\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mlocal_download_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m sagemaker_session\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mlocal_download_dir\n\u001b[1;32m    540\u001b[0m )\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _tmpdir(directory\u001b[38;5;241m=\u001b[39mlocal_download_dir) \u001b[38;5;28;01mas\u001b[39;00m tmp:\n\u001b[0;32m--> 542\u001b[0m     model_dir \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msagemaker_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m     _create_or_update_code_dir(\n\u001b[1;32m    545\u001b[0m         model_dir,\n\u001b[1;32m    546\u001b[0m         inference_script,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m         tmp,\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    553\u001b[0m     tmp_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp-model.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/utils.py:633\u001b[0m, in \u001b[0;36m_extract_model\u001b[0;34m(model_uri, sagemaker_session, tmp)\u001b[0m\n\u001b[1;32m    631\u001b[0m     local_model_path \u001b[38;5;241m=\u001b[39m model_uri\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(name\u001b[38;5;241m=\u001b[39mlocal_model_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr:gz\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m--> 633\u001b[0m     \u001b[43mcheck_tarfile_data_filter_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     t\u001b[38;5;241m.\u001b[39mextractall(path\u001b[38;5;241m=\u001b[39mtmp_model_dir, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tmp_model_dir\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/utils.py:1511\u001b[0m, in \u001b[0;36mcheck_tarfile_data_filter_attribute\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# The function and it's usages can be deprecated post support of python >= 3.12\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tarfile, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_filter\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PythonVersionError(\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSince tarfile extraction is unsafe the operation is prohibited \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mper PEP-721. Please update your Python [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msys\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto latest patch [refer to https://www.python.org/downloads/] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto consume the security patch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1516\u001b[0m     )\n",
      "\u001b[0;31mPythonVersionError\u001b[0m: Since tarfile extraction is unsafe the operation is prohibited per PEP-721. Please update your Python [3.10.6 (main, Oct  7 2022, 20:19:58) [GCC 11.2.0]] to latest patch [refer to https://www.python.org/downloads/] to consume the security patch"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.pytorch.model import PyTorchModel # PyTorch model\n",
    "\n",
    "# define paths\n",
    "model_data = f\"{output_location}/{job_name}/output/model.tar.gz\" # trained model artifacts\n",
    "transformer_input = f\"{s3_split_dest}batch/images\" # batch directory for input data\n",
    "transformer_output = f\"{output_location}/{job_name}/output/transformer\" # transformer job results\n",
    "\n",
    "# create a PyTorch model\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_data, # trained model artifacts\n",
    "    role=role,\n",
    "    entry_point='inference.py', # custom inference script, locate in code directory\n",
    "    framework_version='2.1.0', # CPU - Python 3.10\n",
    "    py_version='py310',\n",
    "    source_dir='code',\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# create a transformer from the PyTorch model\n",
    "transformer = pytorch_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=transformer_output,\n",
    "    accept='application/json',\n",
    "    max_payload=10\n",
    ")\n",
    "\n",
    "# begin batch transform job\n",
    "transformer.transform(\n",
    "    data=transformer_input,\n",
    "    content_type='image/jpeg'\n",
    ")\n",
    "\n",
    "# wait for job to complete\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad8656-c7fa-40a3-bcae-fe854e846ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # encoder and decoder\n",
    "# define s3 client\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "# define prefix for transformer job output\n",
    "transformer_output_s3_prefix = transformer_output.replace(\n",
    "    f\"s3://{bucket}/\", \"\"\n",
    ")\n",
    "\n",
    "# get job output files from bucket\n",
    "objects_in_bucket = s3_client.list_objects(\n",
    "    Bucket=bucket, Prefix=transformer_output_s3_prefix\n",
    ")\n",
    "\n",
    "# define function to convert an s3 file to dataframe\n",
    "def s3_file_to_df(key):\n",
    "    \n",
    "    # get single s3 file\n",
    "    s3_file = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    \n",
    "    # decode, read, and create list of json strings\n",
    "    body = s3_file['Body'].read().decode('utf-8')\n",
    "    json_strings = json.loads(body)\n",
    "    \n",
    "    # create list for data to create dataframe\n",
    "    data_list = []\n",
    "\n",
    "    # parse json strings and append to data list\n",
    "    for json_str in json_strings:\n",
    "        json_obj = json.loads(json_str)\n",
    "        data_list.append(json_obj)\n",
    "        \n",
    "    # create dataframe\n",
    "    df = pd.DataFrame(data_list)\n",
    "    \n",
    "    # insert column for sample id, obtained from s3 filename\n",
    "    df.insert(0, 'sample_id', key.split(\"/\")[-1].split(\".\")[0])\n",
    "    return df\n",
    "\n",
    "# create list to store dataframes for concatenation\n",
    "df_list = []\n",
    "\n",
    "# iterate through each object in s3 bucket\n",
    "for obj in objects_in_bucket.get('Contents', []):\n",
    "    \n",
    "    # get filename\n",
    "    s3_filename = obj['Key']\n",
    "\n",
    "    # skip over any files without expected '.out' file extension\n",
    "    if s3_filename.endswith('.out'):\n",
    "\n",
    "        # call function to create dataframe of current file contents\n",
    "        df_current_file = s3_file_to_df(s3_filename)\n",
    "        \n",
    "        # insert column for timestamp\n",
    "        df_current_file.insert(0, 'timestamp', obj['LastModified'])\n",
    "\n",
    "        # append to dataframe list for concatenation\n",
    "        df_list.append(df_current_file)\n",
    "\n",
    "# concatenate dataframes to create end result\n",
    "df_batch_transform = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# convert class id to int\n",
    "df_batch_transform['class_id'] = df_batch_transform['class_id'].astype(int)\n",
    "\n",
    "# display dataframe\n",
    "df_batch_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77faa367-d273-45d1-afde-57a498308ccc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example Business Problem Query\n",
    "\n",
    "Query the dataframe to obtain number of detections of each class we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e1395-e5f7-4015-af82-ae237620233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe copy\n",
    "df_business_query = df_batch_transform.copy()\n",
    "\n",
    "# add a date column in YYYY-MM-DD format derived from timestamp\n",
    "df_business_query['date'] = df_batch_transform['timestamp'].dt.date\n",
    "\n",
    "# create new dataframe with business query results\n",
    "df_business_query = pd.DataFrame(df_business_query.groupby(['date', 'class_id', 'class_name']).size().reset_index(name='detections'))\n",
    "\n",
    "# filter out class id of 1 for 'vest'\n",
    "df_business_query = df_business_query.query('class_id != 1')\n",
    "\n",
    "# display dataframe\n",
    "df_business_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c430b-eaae-4dd7-b143-97d81c362b1a",
   "metadata": {},
   "source": [
    "# Monitors\n",
    "Quality monitors help detect issues such as concept drift, data drift, or model degradation over time, enabling timely corrective actions to maintain the performance and reliability of machine learning systems.\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee937572-2dbf-4cc4-bb1f-3a7123b331dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker import get_execution_role, session, Session\n",
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import BatchDataCaptureConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92470a8b-eaf6-4cd1-8b08-9d84ecd6021e",
   "metadata": {},
   "source": [
    "### Capture Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f4ebd-8252-431f-9a08-888aad9c033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the S3 URI where captured data will be stored\n",
    "data_capture_destination = \"s3://sagemaker-us-east-1-752648173624/safety/data/monitor/captured_data\" # \"s3://captured_data_S3_uri\" # Replace with actual S3 URI\n",
    "\n",
    "# Define the model name for data capture\n",
    "model_name = \"monitor_model\" # model name\n",
    "\n",
    "# Initialize a Transformer object for capturing data during inference\n",
    "transformer = Transformer(model_name=model_name)\n",
    "transform_arg = transformer.transform(\n",
    "    batch_data_capture_config=BatchDataCaptureConfig(\n",
    "        destination_s3_uri=data_capture_destination,\n",
    "        # kms_key_id=\"kms_key\", # Replace with actual KMS key ID (OPTIONAL)\n",
    "        generate_inference_id=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267e93c-b19a-4f65-89b1-5d04b99e50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for captured data, output reports, ground truth, statistics, and constraints\n",
    "s3_capture_upload_path = \"s3://sagemaker-us-east-1-752648173624/safety/data/monitor/upload\"\n",
    "s3_report_path = \"s3://sagemaker-us-east-1-752648173624/safety/data/monitor/report\"\n",
    "gt_s3_uri = \"s3://sagemaker-us-east-1-752648173624/safety/data/monitor/groundtruth\"\n",
    "\n",
    "# statistics_path = \"statistics.json\" # not manditory\n",
    "# constraints_path = \"constraints.json\" # not manditory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9162d14-5ddc-4566-a14b-7a99cb2cc508",
   "metadata": {},
   "source": [
    "Once the transform job completes, the captured data gets logged under the DestinationS3Uri provided with the data capture configuration.\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf4eca2-8427-48ae-9e83-58138b1aa354",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implement data Quality monitors on ML system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d46ade-de6e-4c37-9425-28420c387734",
   "metadata": {},
   "source": [
    "#### Create Baseline\n",
    "Create a baseline job that compares your model predictions with ground truth labels in a baseline dataset that you have stored in Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa574ae0-0cec-46b2-867c-9a05e4e55f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline job to suggest baseline statistics and constraints\n",
    "baseline_results_uri = data_capture_destination # location of the baseline results\n",
    "baseline_data = transformer_output # locaion of the baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37e375-e098-46b1-8e28-4a6947870107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create a DefaultModelMonitor for data quality monitoring\n",
    "data_quality_model_monitor = DefaultModelMonitor(role=get_execution_role())\n",
    "\n",
    "data_quality_model_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7598c-e7be-40c5-87d0-37b7a972b24d",
   "metadata": {},
   "source": [
    "#### Schedule data quality monitoring jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d90b67-d69f-4ea2-a30e-6e22cdbcea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule data quality monitoring jobs\n",
    "baseline_data_job_name = \"baseline_data_job\"  # Define the baseline job name\n",
    "\n",
    "schedule = data_quality_model_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=baseline_data_job_name,\n",
    "    batch_transform_input=BatchTransformInput(\n",
    "        data_captured_destination_s3_uri=s3_capture_upload_path,\n",
    "        destination=\"/opt/ml/processing/input\", # ~not sure\n",
    "        dataset_format=MonitoringDatasetFormat.csv(header=False),\n",
    "    ),\n",
    "    output_s3_uri=s3_report_path,\n",
    "    # statistics=statistics_path, # not manditory\n",
    "    # constraints=constraints_path, # not manditory\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040250ec-1594-4aa5-b939-f0e454a3083c",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a83de8-a569-45e1-a79a-95f19eeff868",
   "metadata": {},
   "source": [
    "### Implement model Quality monitors on ML system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4ee75-c7a3-4c05-9640-9fbafed2f941",
   "metadata": {},
   "source": [
    "#### Create Baseline\n",
    "Create a baseline job that compares your model predictions with ground truth labels in a baseline dataset that you have stored in Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7904b3-e276-4a36-89a7-4ae68c25a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create a ModelQualityMonitor for model quality monitoring\n",
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e584ef-8dad-44fd-8c43-53dd8efbe40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline job to suggest baseline statistics and constraints for model quality monitoring\n",
    "baseline_model_job_name = \"baseline_model_job\"  # Define the baseline job name\n",
    "\n",
    "job = model_quality_monitor.suggest_baseline(\n",
    "    job_name=baseline_model_job_name,\n",
    "    baseline_dataset=baseline_data,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    problem_type='BinaryClassification',\n",
    "    inference_attribute=\"class_name\", # The column in the dataset that contains predictions. ~not sure\n",
    "    probability_attribute=\"confidence\", # The column in the dataset that contains probabilities. ~not sure\n",
    "    ground_truth_attribute=\"class_id\" # The column in the dataset that contains ground truth labels. ~not sure\n",
    ")\n",
    "job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c632e2a-89a2-4d07-9cd2-d27134d71c1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Schedule data quality monitoring jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543d463-80b1-446a-b0fe-8c436cc91cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quality_model_monitor = ModelQualityMonitor(\n",
    "   role=sagemaker.get_execution_role(),\n",
    ")\n",
    "\n",
    "# Schedule model quality monitoring jobs\n",
    "mon_schedule_name = \"model_quality_schedule\"  # Define the model quality monitoring schedule name\n",
    "schedule = model_quality_model_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    batch_transform_input=BatchTransformInput(\n",
    "        data_captured_destination_s3_uri=s3_capture_upload_path,\n",
    "        destination=\"/opt/ml/processing/input\", # not sure (storage location?)\n",
    "        dataset_format=MonitoringDatasetFormat.csv(header=False),\n",
    "        probability_attribute=\"0\",\n",
    "        probability_threshold_attribute=0.5, # the threshold to classify the inference probablity to class 0 or 1 in \n",
    "        start_time_offset=\"-PT6H\", # look back 6 hour for transform job outputs.\n",
    "        end_time_offset=\"-PT0H\"\n",
    "    ),\n",
    "    ground_truth_input=gt_s3_uri,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    constraints=constraints_path, #baseline_job.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bf37a2-26d6-4b40-8072-1931e602d2a5",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe612a-7ddf-471e-b8e3-8b0963a802bf",
   "metadata": {},
   "source": [
    "### Implement infrastructure monitors on ML system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e5c62-83a3-42a1-a6bb-1c71d7b6e2b7",
   "metadata": {},
   "source": [
    "https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Lambda-Insights-Getting-Started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856654b-70fe-4a40-8cc7-6797abdd27a2",
   "metadata": {},
   "source": [
    "### Create a monitoring dashboard for your ML endpoint/job on CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243ee81-edf5-4630-bb49-f6a23e5afa04",
   "metadata": {},
   "source": [
    "https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/create_dashboard.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f50686-9823-4f2e-8db1-523f407929d1",
   "metadata": {},
   "source": [
    "### Generate model and data reports on SageMaker.\n",
    "\n",
    "from the dashboard"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
