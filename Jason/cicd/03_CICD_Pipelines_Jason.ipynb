{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# 03 - CI/CD Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyathena in /opt/conda/lib/python3.10/site-packages (3.3.0)\n",
      "Requirement already satisfied: boto3>=1.26.4 in /opt/conda/lib/python3.10/site-packages (from pyathena) (1.33.9)\n",
      "Requirement already satisfied: botocore>=1.29.4 in /opt/conda/lib/python3.10/site-packages (from pyathena) (1.33.9)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from pyathena) (2022.7.1)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from pyathena) (8.0.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.26.4->pyathena) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.26.4->pyathena) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore>=1.29.4->pyathena) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore>=1.29.4->pyathena) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.29.4->pyathena) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.208.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.33.9)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.2)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.25.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.1.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.1)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.20.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.5.2)\n",
      "Requirement already satisfied: tblib<3,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.0.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.31.0)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.64.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker) (5.9.0)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.9 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.33.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker->sagemaker) (0.58.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (2023.11.17)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.31.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pyathena\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3 # aws sdk for python\n",
    "import sagemaker # machine learning platform\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "import sys\n",
    "\n",
    "import json # encoder and decoder\n",
    "import numpy as np # array manipulation\n",
    "import os # operating system interfaces\n",
    "import pandas as pd # python data analysis\n",
    "import re # regular expressions\n",
    "from pyathena import connect # athena client\n",
    "from sagemaker.pytorch.estimator import PyTorch # PyTorch estimator\n",
    "from sagemaker.pytorch.model import PyTorchModel # PyTorch model\n",
    "from time import gmtime, strftime, sleep # time-related functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "model_package_group_name = f\"SafetyModelPackageGroupName\"\n",
    "\n",
    "# define prefixes for the safety catalog and data directories\n",
    "prefix_catalog = 'safety/catalog'\n",
    "prefix_data = 'safety/data'\n",
    "\n",
    "# print s3 locations\n",
    "#print('Data directory location:', f\"s3://{default_bucket}/{prefix_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Input Data Using Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query SELECT statement:\n",
      " SELECT * FROM safetydb.catalog_csv\n",
      "    WHERE img_filename like '%.jpg'\n",
      "    AND label_filename like '%.txt'\n",
      "    LIMIT 100\n"
     ]
    }
   ],
   "source": [
    "# define database name\n",
    "database_name = 'safetydb'\n",
    "\n",
    "# define table name\n",
    "table_name_csv = 'catalog_csv'\n",
    "\n",
    "# set s3 temporary staging directory\n",
    "s3_staging_dir = \"s3://{0}/athena/staging\".format(default_bucket)\n",
    "\n",
    "# define connection parameters\n",
    "conn = connect(region_name=region, s3_staging_dir=s3_staging_dir)\n",
    "\n",
    "# define sql query statement\n",
    "statement = \"\"\"SELECT * FROM {}.{}\n",
    "    WHERE img_filename like '%.jpg'\n",
    "    AND label_filename like '%.txt'\n",
    "    LIMIT 100\"\"\".format(\n",
    "    database_name, table_name_csv\n",
    ")\n",
    "\n",
    "# print sql statement for review before executing\n",
    "print('SQL query SELECT statement:\\n', statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/1054740236.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_catalog_query = pd.read_sql(statement, conn)\n"
     ]
    }
   ],
   "source": [
    "# execute sql query and display results\n",
    "df_catalog_query = pd.read_sql(statement, conn)\n",
    "#df_catalog_query.head(10)\n",
    "\n",
    "df_catalog_query.to_csv(f\"data/catalog_query.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-414754026690/safety/catalog/catalog_query.csv\n"
     ]
    }
   ],
   "source": [
    "local_path = \"data/catalog_query.csv\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "catalog_uri = f\"s3://{default_bucket}/{prefix_catalog}\"\n",
    "\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=catalog_uri,\n",
    ")\n",
    "\n",
    "print(input_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-414754026690/safety/data/split_cicd/batch/images\n"
     ]
    }
   ],
   "source": [
    "batch_data_uri = f\"s3://{default_bucket}/{prefix_data}/split_cicd/batch/images\"\n",
    "\n",
    "print(batch_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.r5.xlarge\" # memory optimized\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=batch_data_uri,\n",
    ")\n",
    "\n",
    "map_threshold = ParameterFloat(name=\"mAPThreshold\", default_value=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Processing Step for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "import argparse\n",
    "#import os\n",
    "#import requests\n",
    "#import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.pipeline import Pipeline\n",
    "import subprocess\n",
    "\n",
    "# define function to copy files for respective data splits to corresponding s3 destinations\n",
    "# provide 'split_name' as either 'train', 'val', 'test', or 'batch'\n",
    "# provide 'split_list' as either 'train_list', 'val_list', 'test_list', or 'batch_list'\n",
    "def split_dataset(split_name, split_list):\n",
    "    \n",
    "    # counter for printing copy progress\n",
    "    num_files_copied = 0\n",
    "\n",
    "    # iterate through each sample in split\n",
    "    for index, sample in data[split_list].iterrows():\n",
    "\n",
    "        # source/destination variables for individual sample\n",
    "        cp_image_source = f\"{s3_images_source}{sample['img_filename']}\"\n",
    "        cp_image_dest = f\"{s3_split_dest}{split_name}/images/\"\n",
    "        cp_label_source = f\"{s3_labels_source}{sample['label_filename']}\"\n",
    "        cp_label_dest = f\"{s3_split_dest}{split_name}/labels/\"\n",
    "\n",
    "        # copy from source to destination\n",
    "        #!aws s3 cp $cp_image_source $cp_image_dest --exclude \"*\" --include \"*.jpg\" --only-show-errors\n",
    "        #!aws s3 cp $cp_label_source $cp_label_dest --exclude \"*\" --include \"*.txt\" --only-show-errors\n",
    "        \"\"\"\n",
    "        subprocess.run(f\"aws s3 cp {cp_image_source} {cp_image_dest} --exclude '*' --include '*.jpg' --only-show-errors\", shell=True)\n",
    "        subprocess.run(f\"aws s3 cp {cp_label_source} {cp_label_dest} --exclude '*' --include '*.txt' --only-show-errors\", shell=True)\n",
    "        \n",
    "        # increment counter\n",
    "        num_files_copied += 1\n",
    "\n",
    "        # print status after every 500 files copied\n",
    "        if num_files_copied % 10 == 0:\n",
    "            print(f\"{num_files_copied} files copied.\")\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--s3-images-source', type=str)\n",
    "    parser.add_argument('--s3-labels-source', type=str)\n",
    "    parser.add_argument('--s3-split-dest', type=str)\n",
    "    \n",
    "    # obtain arguments\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "    \n",
    "    data = pd.read_csv(\n",
    "        f\"{base_dir}/input/catalog_query.csv\"\n",
    "    )\n",
    "    \n",
    "    # data split in four sets - training, validation, test, and batch inference\n",
    "    rand_split = np.random.rand(len(data))\n",
    "    train_list = rand_split < 0.4\n",
    "    val_list = (rand_split >= 0.4) & (rand_split < 0.5)\n",
    "    test_list = (rand_split >= 0.5) & (rand_split < 0.6)\n",
    "    batch_list = rand_split >= 0.6 # \"production\" data\n",
    "\n",
    "    # print data splits\n",
    "    print('Data Splits:')\n",
    "    print('------------')\n",
    "    print(f\"Train :   {sum(train_list)} samples\")\n",
    "    print(f\"Val   :   {sum(val_list)} samples\")\n",
    "    print(f\"Test  :   {sum(test_list)} samples\")\n",
    "    print(f\"Batch :   {sum(batch_list)} samples\")\n",
    "    \n",
    "    # define and print source s3 locations\n",
    "    #s3_images_source = f\"s3://{default_bucket}/{prefix_data}/images/\"\n",
    "    #s3_labels_source = f\"s3://{default_bucket}/{prefix_data}/labels/\"\n",
    "    s3_images_source = args.s3_images_source\n",
    "    s3_labels_source = args.s3_labels_source\n",
    "    print('Images source directory location:', s3_images_source)\n",
    "    print('Labels source directory location:', s3_labels_source, '\\n')\n",
    "\n",
    "    # define and print destination s3 location for data splits\n",
    "    s3_split_dest = args.s3_split_dest\n",
    "    print('Split destination directory location:', s3_split_dest)\n",
    "    \n",
    "    # perform data copies\n",
    "    print('Beginning TRAIN data split copies.')\n",
    "    split_dataset(split_name='train', split_list=train_list)\n",
    "    print('Completed TRAIN data split copies.\\n')\n",
    "\n",
    "    print('Beginning VAL data split copies.')\n",
    "    split_dataset(split_name='val', split_list=val_list)\n",
    "    print('Completed VAL data split copies.\\n')\n",
    "\n",
    "    print('Beginning TEST data split copies.')\n",
    "    split_dataset(split_name='test', split_list=test_list)\n",
    "    print('Completed TEST data split copies.\\n')\n",
    "\n",
    "    print('Beginning BATCH data split copies.')\n",
    "    split_dataset(split_name='batch', split_list=batch_list)\n",
    "    print('Completed BATCH data split copies.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "\n",
    "#Initialize the PyTorchProcessor\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='2.1.0',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=processing_instance_count,\n",
    "    py_version='py310',\n",
    "    #source_dir='code',\n",
    "    base_job_name='pytorch-safety-process',\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\noutputs=[\\n    ProcessingOutput(output_name=\"training\", source=f\"s3://{default_bucket}/{prefix_data}/split_cicd/\"), #\"/opt/ml/processing/training\"),\\n    #ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\\n    #ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\\n],\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processor_args = pytorch_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    arguments=[\"--s3-images-source\", f\"s3://{default_bucket}/{prefix_data}/images/\",\n",
    "                   \"--s3-labels-source\", f\"s3://{default_bucket}/{prefix_data}/labels/\",\n",
    "                   \"--s3-split-dest\", f\"s3://{default_bucket}/{prefix_data}/split_cicd/\"\n",
    "    ],\n",
    "    code=\"preprocessing.py\",\n",
    "    source_dir='code',\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"SafetyProcess\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Training Step to Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "#model_path = f\"s3://{default_bucket}/SafetyTrain\"\n",
    "\n",
    "# define job name and output location, 'bm' for benchmark\n",
    "job_name = 'yolov8-cicd' # + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_location = \"s3://{}/{}/output/{}\".format(default_bucket, prefix_data, job_name)\n",
    "\n",
    "# build a PyTorch estimator\n",
    "pytorch_estimator = PyTorch(\n",
    "    role=role,\n",
    "    entry_point='train.py', # custom training script, locate in code directory\n",
    "    framework_version='2.1.0', # training - CPU - Python 3.10\n",
    "    py_version='py310',\n",
    "    source_dir='code',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=pipeline_session, # pipeline session\n",
    "    hyperparameters = {'data': 'data.yaml', # yaml config file for custom dataset\n",
    "                       'epochs': 1, # number of training epochs\n",
    "                       'batch': 32, # batch size, -1 for AutoBatch\n",
    "                       'yolo_model': 'yolov8n.pt', # pretrained base model\n",
    "                       'saved_model_weights': 'model.pt' # saved model weights\n",
    "                      }\n",
    ")\n",
    "\n",
    "# s3 location where training data is saved\n",
    "# inputs = s3_split_dest[:-1]\n",
    "inputs = f\"s3://{default_bucket}/{prefix_data}/split_cicd\"\n",
    "\n",
    "# begin training job\n",
    "train_args = pytorch_estimator.fit(inputs=inputs, job_name=job_name, logs='All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"SafetyTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Model Evaluation Step to Evaluate the Trained Model\n",
    "\n",
    "First, develop an evaluation script that is specified in a Processing step that performs the model evaluation.\n",
    "\n",
    "After pipeline execution, you can examine the resulting `evaluation.json` for analysis.\n",
    "\n",
    "The evaluation script uses `xgboost` to do the following:\n",
    "\n",
    "* Load the model.\n",
    "* Read the test data.\n",
    "* Issue predictions against the test data.\n",
    "* Build a classification report, including accuracy and ROC curve.\n",
    "* Save the evaluation report to the evaluation directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluation.py\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "import argparse\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--data', type=str, default='data-eval.yaml') # yaml config file for custom dataset\n",
    "\n",
    "    # obtain arguments\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    model_path = '/opt/ml/processing/model/model.tar.gz'\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\"/opt/ml/processing/model/\")\n",
    "\n",
    "    #model = pickle.load(open(\"model.pt\", \"rb\"))\n",
    "    \n",
    "    # evaluate model on test dataset\n",
    "    print('EVALUATING MODEL ON TEST DATASET...')\n",
    "    model_val = YOLO('/opt/ml/processing/model/model.pt')\n",
    "    metrics = model_val.val(data=args.data, split='test')\n",
    "    \n",
    "    # print evaluation metric to compare performance between models\n",
    "    print('-------------')\n",
    "    print('-------------')\n",
    "    print('-------------')\n",
    "    print('MODEL EVALUATION METRIC:')\n",
    "    print('mAP50:', round(metrics.box.map50, 4))\n",
    "    print('-------------')\n",
    "    print('-------------')\n",
    "    print('-------------')\n",
    "    \n",
    "    \n",
    "    map50 = round(metrics.box.map50, 4)\n",
    "\n",
    "    report_dict = {\n",
    "        \"detection_metrics\": {\n",
    "            \"mAP50\": {\"value\": map50},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, create an instance of a `ScriptProcessor` processor and use it in the `ProcessingStep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize the PyTorchProcessor\n",
    "pytorch_processor_eval = PyTorchProcessor(\n",
    "    framework_version='2.1.0',\n",
    "    role=role,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=processing_instance_count,\n",
    "    py_version='py310',\n",
    "    #source_dir='code',\n",
    "    base_job_name='pytorch-safety-eval',\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "eval_args = pytorch_processor_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=inputs, #step_process.properties.ProcessingOutputConfig.Outputs[\"training\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input/code/datasets\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"evaluation.py\",\n",
    "    source_dir='code',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"SafetyEval\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Create Model Step to Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trained model artifacts\n",
    "#model_data = step_train.properties.ModelArtifacts.S3ModelArtifacts\n",
    "model_data = f\"s3://sagemaker-us-east-1-414754026690/safety/data/output/yolov8-cicd/pipelines-kqrcqmtvskqa-SafetyTrain-yS7q405iW7/output/model.tar.gz\"\n",
    "\n",
    "# create a PyTorch model\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_data, # trained model artifacts\n",
    "    role=role,\n",
    "    entry_point='inference.py', # custom inference script, locate in code directory\n",
    "    framework_version='1.3',\n",
    "    py_version='py3',\n",
    "    source_dir='code',\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the `ModelStep` by providing the return values from `model.create()` as the step arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-414754026690/safety/data/output/yolov8-cicd/pipelines-kqrcqmtvskqa-SafetyTrain-yS7q405iW7/output/model.tar.gz), script artifact (code), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-414754026690/pytorch-inference-eia-2024-02-19-00-40-30-778/model.tar.gz. This may take some time depending on model size...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nstep_create_model = ModelStep(\\n    name=\"SafetyCreateModel\",\\n    model=pytorch_model,\\n    inputs=CreateModelInput(instance_type=\"ml.m5.large\", accelerator_type=\"ml.eia1.medium\"),\\n)\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "#from sagemaker.model import Model # not sure if needed\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"SafetyCreateModel\",\n",
    "    step_args=pytorch_model.create(instance_type=\"ml.m5.xlarge\", accelerator_type=\"ml.eia1.medium\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Transform Step to Perform Batch Transformation\n",
    "\n",
    "Now that a model instance is defined, create a `Transformer` instance with the appropriate model type, compute instance type, and desired output S3 URI.\n",
    "\n",
    "Specifically, pass in the `ModelName` from the `CreateModelStep`, `step_create_model` properties. The `CreateModelStep` `properties` attribute matches the object model of the [DescribeModel](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeModel.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "transformer_output = f\"s3://{default_bucket}/SafetyTransform\" # transformer job results\n",
    "\n",
    "# create a transformer from the PyTorch model\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path=transformer_output,\n",
    "    accept='application/json',\n",
    "    max_payload=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pass in the transformer instance and the `TransformInput` with the `batch_data` pipeline parameter defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"SafetyTransform\", transformer=transformer, inputs=TransformInput(data=batch_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Register Model Step to Create a Model Package\n",
    "\n",
    "A model package is an abstraction of reusable model artifacts that packages all ingredients required for inference. Primarily, it consists of an inference specification that defines the inference image to use along with an optional model weights location.\n",
    "\n",
    "A model package group is a collection of model packages. A model package group can be created for a specific ML business problem, and new versions of the model packages can be added to it. Typically, customers are expected to create a ModelPackageGroup for a SageMaker pipeline so that model package versions can be added to the group for every SageMaker Pipeline run.\n",
    "\n",
    "To register a model in the Model Registry, we take the model created in the previous steps\n",
    "```\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "```\n",
    "and call the `.register()` function on it while passing all the parameters needed for registering the model.\n",
    "\n",
    "We take the outputs of the `.register()` call and pass that to the `ModelStep` as step arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n",
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-414754026690/safety/data/output/yolov8-cicd/pipelines-kqrcqmtvskqa-SafetyTrain-yS7q405iW7/output/model.tar.gz), script artifact (code), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-414754026690/pytorch-inference-2024-02-19-01-46-49-736/model.tar.gz. This may take some time depending on model size...\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "#eval_output = step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "#evaluation_s3_uri = f\"{eval_output}/evaluation.json\"\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=f\"s3://sagemaker-us-east-1-414754026690/SafetyPipeline/kqrcqmtvskqa/SafetyEval/output/evaluation/evaluation.json\",\n",
    "        #s3_uri=\"{}/evaluation.json\".format(\n",
    "        #    step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        #),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "register_args = pytorch_model.register(\n",
    "    content_types=[\"image/jpeg\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    "    domain=\"COMPUTER_VISION\"\n",
    ")\n",
    "\n",
    "step_register = ModelStep(name=\"SafetyRegisterModel\", step_args=register_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Fail Step to Terminate the Pipeline Execution and Mark it as Failed\n",
    "\n",
    "This section walks you through the following steps:\n",
    "\n",
    "* Define a `FailStep` with customized error message, which indicates the cause of the execution failure.\n",
    "* Enter the `FailStep` error message with a `Join` function, which appends a static text string with the dynamic `mse_threshold` parameter to build a more informative error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "step_fail = FailStep(\n",
    "    name=\"SafetyMAPFail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to mAP <\", map_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Condition Step to Check Accuracy and Conditionally Create a Model and Run a Batch Transformation and Register a Model in the Model Registry, Or Terminate the Execution in Failed State\n",
    "\n",
    "In this step, the model is registered only if the accuracy of the model, as determined by the evaluation step `step_eval`, exceeded a specified value. Otherwise, the pipeline execution fails and terminates. A `ConditionStep` enables pipelines to support conditional execution in the pipeline DAG based on the conditions of the step properties.\n",
    "\n",
    "In the following section, you:\n",
    "\n",
    "* Define a `ConditionLessThanOrEqualTo` on the accuracy value found in the output of the evaluation step, `step_eval`.\n",
    "* Use the condition in the list of conditions in a `ConditionStep`.\n",
    "* Pass the `CreateModelStep` and `TransformStep` steps, and the `RegisterModel` step collection into the `if_steps` of the `ConditionStep`, which are only executed if the condition evaluates to `True`.\n",
    "* Pass the `FailStep` step into the `else_steps`of the `ConditionStep`, which is only executed if the condition evaluates to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "\n",
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"detection_metrics.mAP50.value\",\n",
    "    ),\n",
    "    right=map_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"SafetyMAPCond\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_register, step_create_model, step_transform],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a Pipeline of Parameters, Steps, and Conditions\n",
    "\n",
    "In this section, combine the steps into a Pipeline so it can be executed.\n",
    "\n",
    "A pipeline requires a `name`, `parameters`, and `steps`. Names must be unique within an `(account, region)` pair.\n",
    "\n",
    "Note:\n",
    "\n",
    "* All the parameters used in the definitions must be present.\n",
    "* Steps passed into the pipeline do not have to be listed in the order of execution. The SageMaker Pipeline service resolves the data dependency DAG as steps for the execution to complete.\n",
    "* Steps must be unique to across the pipeline step list and all condition step if/else lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = f\"SafetyPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        batch_data,\n",
    "        map_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    #steps=[step_process, step_train, step_eval],\n",
    "    #steps=[step_train, step_eval],\n",
    "    #steps=[step_eval],\n",
    "    #steps=[step_eval, step_cond]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (Optional) Examining the pipeline definition\n",
    "\n",
    "The JSON of the pipeline definition can be examined to confirm the pipeline is well-defined and the parameters and step properties resolve correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/86b113c5543c262aefe08b88ae3a4e3d/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/54f0ef6bee583ff9186b762aaf572190/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/88f4f1b66ade82e1fe99e11e78668722/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/2c207c809cb0e0e9a1d77e5247f961f9/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'ProcessingInstanceCount',\n",
       "   'Type': 'Integer',\n",
       "   'DefaultValue': 1},\n",
       "  {'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.r5.xlarge'},\n",
       "  {'Name': 'ModelApprovalStatus',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'PendingManualApproval'},\n",
       "  {'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-us-east-1-414754026690/safety/catalog/catalog_query.csv'},\n",
       "  {'Name': 'BatchData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-us-east-1-414754026690/safety/data/split_cicd/batch/images'},\n",
       "  {'Name': 'mAPThreshold', 'Type': 'Float', 'DefaultValue': 0.001}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'SafetyProcess',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.1.0-cpu-py310',\n",
       "     'ContainerArguments': ['--s3-images-source',\n",
       "      's3://sagemaker-us-east-1-414754026690/safety/data/images/',\n",
       "      '--s3-labels-source',\n",
       "      's3://sagemaker-us-east-1-414754026690/safety/data/labels/',\n",
       "      '--s3-split-dest',\n",
       "      's3://sagemaker-us-east-1-414754026690/safety/data/split_cicd/'],\n",
       "     'ContainerEntrypoint': ['/bin/bash',\n",
       "      '/opt/ml/processing/input/entrypoint/runproc.sh']},\n",
       "    'RoleArn': 'arn:aws:iam::414754026690:role/LabRole',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/86b113c5543c262aefe08b88ae3a4e3d/sourcedir.tar.gz',\n",
       "       'LocalPath': '/opt/ml/processing/input/code/',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'entrypoint',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/54f0ef6bee583ff9186b762aaf572190/runproc.sh',\n",
       "       'LocalPath': '/opt/ml/processing/input/entrypoint',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}]}},\n",
       "  {'Name': 'SafetyTrain',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.1.0-cpu-py310',\n",
       "     'EnableSageMakerMetricsTimeSeries': True},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-414754026690/safety/data/output/yolov8-cicd'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'VolumeSizeInGB': 30,\n",
       "     'InstanceCount': 1,\n",
       "     'InstanceType': 'ml.m5.xlarge'},\n",
       "    'RoleArn': 'arn:aws:iam::414754026690:role/LabRole',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': 's3://sagemaker-us-east-1-414754026690/safety/data/split_cicd',\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ChannelName': 'training'}],\n",
       "    'HyperParameters': {'data': '\"data.yaml\"',\n",
       "     'epochs': '1',\n",
       "     'batch': '32',\n",
       "     'yolo_model': '\"yolov8n.pt\"',\n",
       "     'saved_model_weights': '\"model.pt\"',\n",
       "     'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/58c8b25fbc64e5cbd48e7eec3ea7128e/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"train.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_region': '\"us-east-1\"'},\n",
       "    'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-414754026690/safety/data/output/yolov8-cicd',\n",
       "     'CollectionConfigurations': []},\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-414754026690/safety/data/output/yolov8-cicd',\n",
       "     'DisableProfiler': False}}},\n",
       "  {'Name': 'SafetyEval',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.1.0-cpu-py310',\n",
       "     'ContainerEntrypoint': ['/bin/bash',\n",
       "      '/opt/ml/processing/input/entrypoint/runproc.sh']},\n",
       "    'RoleArn': 'arn:aws:iam::414754026690:role/LabRole',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Steps.SafetyTrain.ModelArtifacts.S3ModelArtifacts'},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-414754026690/safety/data/split_cicd',\n",
       "       'LocalPath': '/opt/ml/processing/input/code/datasets',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/88f4f1b66ade82e1fe99e11e78668722/sourcedir.tar.gz',\n",
       "       'LocalPath': '/opt/ml/processing/input/code/',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'entrypoint',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/2c207c809cb0e0e9a1d77e5247f961f9/runproc.sh',\n",
       "       'LocalPath': '/opt/ml/processing/input/entrypoint',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "          'Values': ['s3:/',\n",
       "           'sagemaker-us-east-1-414754026690',\n",
       "           'SafetyPipeline',\n",
       "           {'Get': 'Execution.PipelineExecutionId'},\n",
       "           'SafetyEval',\n",
       "           'output',\n",
       "           'evaluation']}},\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]},\n",
       "  {'Name': 'SafetyMAPCond',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'GreaterThanOrEqualTo',\n",
       "      'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.SafetyEval.PropertyFiles.EvaluationReport'},\n",
       "        'Path': 'detection_metrics.mAP50.value'}},\n",
       "      'RightValue': {'Get': 'Parameters.mAPThreshold'}}],\n",
       "    'IfSteps': [{'Name': 'SafetyRegisterModel-RegisterModel',\n",
       "      'Type': 'RegisterModel',\n",
       "      'Arguments': {'ModelPackageGroupName': 'SafetyModelPackageGroupName',\n",
       "       'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "          'S3Uri': 's3://sagemaker-us-east-1-414754026690/SafetyPipeline/kqrcqmtvskqa/SafetyEval/output/evaluation/evaluation.json'}},\n",
       "        'Bias': {},\n",
       "        'Explainability': {}},\n",
       "       'Domain': 'COMPUTER_VISION',\n",
       "       'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.3-cpu-py3',\n",
       "          'Environment': {'SAGEMAKER_PROGRAM': 'inference.py',\n",
       "           'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code',\n",
       "           'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "           'SAGEMAKER_REGION': 'us-east-1'},\n",
       "          'ModelDataUrl': 's3://sagemaker-us-east-1-414754026690/pytorch-inference-2024-02-19-01-46-49-736/model.tar.gz',\n",
       "          'Framework': 'PYTORCH',\n",
       "          'FrameworkVersion': '1.3'}],\n",
       "        'SupportedContentTypes': ['image/jpeg'],\n",
       "        'SupportedResponseMIMETypes': ['application/json'],\n",
       "        'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium',\n",
       "         'ml.m5.xlarge'],\n",
       "        'SupportedTransformInstanceTypes': ['ml.m5.xlarge']},\n",
       "       'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'},\n",
       "       'SkipModelValidation': 'None'}},\n",
       "     {'Name': 'SafetyCreateModel-CreateModel',\n",
       "      'Type': 'Model',\n",
       "      'Arguments': {'ExecutionRoleArn': 'arn:aws:iam::414754026690:role/LabRole',\n",
       "       'PrimaryContainer': {'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference-eia:1.3-cpu-py3',\n",
       "        'Environment': {'SAGEMAKER_PROGRAM': 'inference.py',\n",
       "         'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code',\n",
       "         'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "         'SAGEMAKER_REGION': 'us-east-1'},\n",
       "        'ModelDataUrl': 's3://sagemaker-us-east-1-414754026690/pytorch-inference-eia-2024-02-19-00-40-30-778/model.tar.gz'}}},\n",
       "     {'Name': 'SafetyTransform',\n",
       "      'Type': 'Transform',\n",
       "      'Arguments': {'ModelName': {'Get': 'Steps.SafetyCreateModel-CreateModel.ModelName'},\n",
       "       'TransformInput': {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "          'S3Uri': {'Get': 'Parameters.BatchData'}}}},\n",
       "       'TransformOutput': {'S3OutputPath': 's3://sagemaker-us-east-1-414754026690/SafetyTransform',\n",
       "        'Accept': 'application/json'},\n",
       "       'TransformResources': {'InstanceCount': 1,\n",
       "        'InstanceType': 'ml.m5.xlarge'},\n",
       "       'MaxPayloadInMB': 10}}],\n",
       "    'ElseSteps': [{'Name': 'SafetyMAPFail',\n",
       "      'Type': 'Fail',\n",
       "      'Arguments': {'ErrorMessage': {'Std:Join': {'On': ' ',\n",
       "         'Values': ['Execution failed due to mAP >',\n",
       "          {'Get': 'Parameters.mAPThreshold'}]}}}}]}}]}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Submit the pipeline definition to the Pipeline service. The Pipeline service uses the role that is passed in to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/86b113c5543c262aefe08b88ae3a4e3d/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/54f0ef6bee583ff9186b762aaf572190/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/88f4f1b66ade82e1fe99e11e78668722/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/2c207c809cb0e0e9a1d77e5247f961f9/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/86b113c5543c262aefe08b88ae3a4e3d/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/54f0ef6bee583ff9186b762aaf572190/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded code to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/88f4f1b66ade82e1fe99e11e78668722/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-414754026690/SafetyPipeline/code/2c207c809cb0e0e9a1d77e5247f961f9/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TransformJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:414754026690:pipeline/SafetyPipeline',\n",
       " 'ResponseMetadata': {'RequestId': '490808ca-7358-4250-ab49-c24c948aeef7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '490808ca-7358-4250-ab49-c24c948aeef7',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '82',\n",
       "   'date': 'Mon, 19 Feb 2024 02:16:42 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start the pipeline and accept all the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pipeline Operations: Examining and Waiting for Pipeline Execution\n",
    "\n",
    "Describe the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:414754026690:pipeline/SafetyPipeline',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:414754026690:pipeline/SafetyPipeline/execution/karjsh3p6g92',\n",
       " 'PipelineExecutionDisplayName': 'execution-1708309007967',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'PipelineExperimentConfig': {'ExperimentName': 'safetypipeline',\n",
       "  'TrialName': 'karjsh3p6g92'},\n",
       " 'CreationTime': datetime.datetime(2024, 2, 19, 2, 16, 47, 834000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 2, 19, 2, 16, 47, 834000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:414754026690:user-profile/d-kv43uh6emydw/jraimondi',\n",
       "  'UserProfileName': 'jraimondi',\n",
       "  'DomainId': 'd-kv43uh6emydw'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:414754026690:user-profile/d-kv43uh6emydw/jraimondi',\n",
       "  'UserProfileName': 'jraimondi',\n",
       "  'DomainId': 'd-kv43uh6emydw'},\n",
       " 'ResponseMetadata': {'RequestId': 'fe5b1c39-fc88-410c-8639-e5517cc876c0',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fe5b1c39-fc88-410c-8639-e5517cc876c0',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '793',\n",
       "   'date': 'Mon, 19 Feb 2024 02:16:52 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wait for the execution to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexecution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline.py:957\u001b[0m, in \u001b[0;36m_PipelineExecution.wait\u001b[0;34m(self, delay, max_attempts)\u001b[0m\n\u001b[1;32m    928\u001b[0m model \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mwaiter\u001b[38;5;241m.\u001b[39mWaiterModel(\n\u001b[1;32m    929\u001b[0m     {\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    952\u001b[0m     }\n\u001b[1;32m    953\u001b[0m )\n\u001b[1;32m    954\u001b[0m waiter \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mwaiter\u001b[38;5;241m.\u001b[39mcreate_waiter_with_client(\n\u001b[1;32m    955\u001b[0m     waiter_id, model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39msagemaker_client\n\u001b[1;32m    956\u001b[0m )\n\u001b[0;32m--> 957\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPipelineExecutionArn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/waiter.py:55\u001b[0m, in \u001b[0;36mcreate_waiter_with_client.<locals>.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mWaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/waiter.py:393\u001b[0m, in \u001b[0;36mWaiter.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m         reason \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax attempts exceeded. Previously accepted state: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    386\u001b[0m             \u001b[38;5;241m%\u001b[39m (acceptor\u001b[38;5;241m.\u001b[39mexplanation)\n\u001b[1;32m    387\u001b[0m         )\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaiterError(\n\u001b[1;32m    389\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    390\u001b[0m         reason\u001b[38;5;241m=\u001b[39mreason,\n\u001b[1;32m    391\u001b[0m         last_response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    392\u001b[0m     )\n\u001b[0;32m--> 393\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_amount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "List the steps in the execution. These are the steps in the pipeline that have been resolved by the step executor service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'SafetyTransform',\n",
       "  'StartTime': datetime.datetime(2024, 2, 19, 2, 25, 36, 950000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Executing',\n",
       "  'AttemptCount': 1,\n",
       "  'Metadata': {'TransformJob': {'Arn': 'arn:aws:sagemaker:us-east-1:414754026690:transform-job/pipelines-karjsh3p6g92-SafetyTransform-tqxkr0T9HB'}}},\n",
       " {'StepName': 'SafetyCreateModel-CreateModel',\n",
       "  'StartTime': datetime.datetime(2024, 2, 19, 2, 25, 34, 898000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 2, 19, 2, 25, 36, 440000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 1,\n",
       "  'Metadata': {'Model': {'Arn': 'arn:aws:sagemaker:us-east-1:414754026690:model/pipelines-karjsh3p6g92-safetycreatemodel-cr-wsbew7qi5i'}}},\n",
       " {'StepName': 'SafetyRegisterModel-RegisterModel',\n",
       "  'StartTime': datetime.datetime(2024, 2, 19, 2, 25, 34, 898000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 2, 19, 2, 25, 36, 152000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 1,\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:414754026690:model-package/SafetyModelPackageGroupName/1'}}},\n",
       " {'StepName': 'SafetyMAPCond',\n",
       "  'StartTime': datetime.datetime(2024, 2, 19, 2, 25, 33, 945000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 2, 19, 2, 25, 34, 266000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 1,\n",
       "  'Metadata': {'Condition': {'Outcome': 'True'}}},\n",
       " {'StepName': 'SafetyEval',\n",
       "  'StartTime': datetime.datetime(2024, 2, 19, 2, 20, 38, 379000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 2, 19, 2, 25, 33, 539000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 1,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:414754026690:processing-job/pipelines-karjsh3p6g92-SafetyEval-3unHU6xvqh'}}},\n",
       " {'StepName': 'SafetyTrain',\n",
       "  'StartTime': datetime.datetime(2024, 2, 19, 2, 16, 49, 191000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 2, 19, 2, 20, 36, 583000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 1,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:414754026690:training-job/pipelines-karjsh3p6g92-SafetyTrain-FcJjpGaRIJ'}}},\n",
       " {'StepName': 'SafetyProcess',\n",
       "  'StartTime': datetime.datetime(2024, 2, 19, 2, 16, 49, 191000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 2, 19, 2, 21, 15, 933000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 1,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:414754026690:processing-job/pipelines-karjsh3p6g92-SafetyProcess-r7M9wnltv7'}}}]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Examining the Evaluation\n",
    "\n",
    "Examine the resulting model evaluation after the pipeline completes. Download the resulting `evaluation.json` file from S3 and print the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "evaluation_json = sagemaker.s3.S3Downloader.read_file(\n",
    "    \"{}/evaluation.json\".format(\n",
    "        step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "    )\n",
    ")\n",
    "pprint(json.loads(evaluation_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Lineage\n",
    "\n",
    "Review the lineage of the artifacts generated by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.lineage.visualizer import LineageTableVisualizer\n",
    "\n",
    "\n",
    "viz = LineageTableVisualizer(sagemaker.session.Session())\n",
    "for execution_step in reversed(execution.list_steps()):\n",
    "    print(execution_step)\n",
    "    display(viz.show(pipeline_execution_step=execution_step))\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parametrized Executions\n",
    "\n",
    "You can run additional executions of the pipeline and specify different pipeline parameters. The `parameters` argument is a dictionary containing parameter names, and where the values are used to override the defaults values.\n",
    "\n",
    "Based on the performance of the model, you might want to kick off another pipeline execution on a compute-optimized instance type and set the model approval status to \"Approved\" automatically. This means that the model package version generated by the `RegisterModel` step is automatically ready for deployment through CI/CD pipelines, such as with SageMaker Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Apart from that, you might also want to adjust the MSE threshold to a smaller value and raise the bar for the accuracy of the registered model. In this case you can override the MSE threshold like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start(parameters=dict(MseThreshold=3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If the MSE threshold is not satisfied, the pipeline execution enters the `FailStep` and is marked as failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    execution.wait()\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
